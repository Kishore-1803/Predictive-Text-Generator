{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6134200d",
   "metadata": {
    "id": "6134200d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "with open(\"corpus.txt\", 'r', encoding='utf-8') as myfile:\n",
    "    mytext = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0d8c7b",
   "metadata": {
    "id": "3f0d8c7b"
   },
   "outputs": [],
   "source": [
    "mytokenizer = Tokenizer()\n",
    "mytokenizer.fit_on_texts([mytext])\n",
    "total_words = len(mytokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67d349f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c67d349f",
    "outputId": "f54b8ef4-2dab-47cd-9499-1ca8d186a99a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'a': 3,\n",
       " 'to': 4,\n",
       " 'and': 5,\n",
       " 'in': 6,\n",
       " 'we': 7,\n",
       " 'that': 8,\n",
       " 'for': 9,\n",
       " 'on': 10,\n",
       " 'deep': 11,\n",
       " 'is': 12,\n",
       " 'neural': 13,\n",
       " 'networks': 14,\n",
       " 'learning': 15,\n",
       " 'with': 16,\n",
       " 'by': 17,\n",
       " 'this': 18,\n",
       " 'as': 19,\n",
       " 'network': 20,\n",
       " 'training': 21,\n",
       " 'be': 22,\n",
       " 'are': 23,\n",
       " 'can': 24,\n",
       " 'an': 25,\n",
       " 'model': 26,\n",
       " 'our': 27,\n",
       " 'data': 28,\n",
       " 'using': 29,\n",
       " 'from': 30,\n",
       " 'which': 31,\n",
       " 'models': 32,\n",
       " 'show': 33,\n",
       " 'based': 34,\n",
       " 'performance': 35,\n",
       " 'have': 36,\n",
       " 'gradient': 37,\n",
       " 'it': 38,\n",
       " 'layers': 39,\n",
       " 'such': 40,\n",
       " 'new': 41,\n",
       " 'dnn': 42,\n",
       " 'results': 43,\n",
       " 'layer': 44,\n",
       " 'method': 45,\n",
       " 'methods': 46,\n",
       " 'approach': 47,\n",
       " 'these': 48,\n",
       " 'or': 49,\n",
       " 'recognition': 50,\n",
       " 'more': 51,\n",
       " 'algorithm': 52,\n",
       " 'parameters': 53,\n",
       " 'function': 54,\n",
       " 'at': 55,\n",
       " 'each': 56,\n",
       " 'not': 57,\n",
       " 'state': 58,\n",
       " 'art': 59,\n",
       " 'paper': 60,\n",
       " 'number': 61,\n",
       " 'large': 62,\n",
       " 'optimization': 63,\n",
       " 'rnn': 64,\n",
       " 'input': 65,\n",
       " 'speech': 66,\n",
       " 'has': 67,\n",
       " 'stochastic': 68,\n",
       " 'propose': 69,\n",
       " 'convolutional': 70,\n",
       " 'features': 71,\n",
       " 'used': 72,\n",
       " 'classification': 73,\n",
       " 'different': 74,\n",
       " 'also': 75,\n",
       " 'been': 76,\n",
       " 'simple': 77,\n",
       " 'algorithms': 78,\n",
       " 'time': 79,\n",
       " 'linear': 80,\n",
       " 'dnns': 81,\n",
       " 'tasks': 82,\n",
       " 'first': 83,\n",
       " 'one': 84,\n",
       " 'functions': 85,\n",
       " 'trained': 86,\n",
       " 'rnns': 87,\n",
       " 'proposed': 88,\n",
       " 'but': 89,\n",
       " 'only': 90,\n",
       " 'error': 91,\n",
       " 'train': 92,\n",
       " 'hidden': 93,\n",
       " 'when': 94,\n",
       " 'than': 95,\n",
       " 'however': 96,\n",
       " 'recurrent': 97,\n",
       " 'units': 98,\n",
       " 'architecture': 99,\n",
       " 'machine': 100,\n",
       " 'standard': 101,\n",
       " 'non': 102,\n",
       " 'pooling': 103,\n",
       " 'dropout': 104,\n",
       " 'framework': 105,\n",
       " 'order': 106,\n",
       " 'convergence': 107,\n",
       " 'information': 108,\n",
       " 'convex': 109,\n",
       " 'their': 110,\n",
       " 'between': 111,\n",
       " 'introduce': 112,\n",
       " 'work': 113,\n",
       " 'well': 114,\n",
       " 'two': 115,\n",
       " 'experiments': 116,\n",
       " 'novel': 117,\n",
       " 'p': 118,\n",
       " 'computation': 119,\n",
       " 'over': 120,\n",
       " 'descent': 121,\n",
       " 'into': 122,\n",
       " 'set': 123,\n",
       " 'other': 124,\n",
       " 'architectures': 125,\n",
       " 'problem': 126,\n",
       " 'learn': 127,\n",
       " 'them': 128,\n",
       " 'unsupervised': 129,\n",
       " 'datasets': 130,\n",
       " 'local': 131,\n",
       " 'problems': 132,\n",
       " 'size': 133,\n",
       " 'both': 134,\n",
       " 'present': 135,\n",
       " 'domain': 136,\n",
       " 'task': 137,\n",
       " 'techniques': 138,\n",
       " 'scale': 139,\n",
       " 'structure': 140,\n",
       " 'while': 141,\n",
       " 'pre': 142,\n",
       " 'use': 143,\n",
       " 'provide': 144,\n",
       " 'recent': 145,\n",
       " 'how': 146,\n",
       " 'representations': 147,\n",
       " 'unit': 148,\n",
       " 'complex': 149,\n",
       " 'single': 150,\n",
       " 'points': 151,\n",
       " 'recently': 152,\n",
       " 'analysis': 153,\n",
       " 'output': 154,\n",
       " 'approaches': 155,\n",
       " 'x': 156,\n",
       " 'processing': 157,\n",
       " 'systems': 158,\n",
       " 'way': 159,\n",
       " 'all': 160,\n",
       " 'many': 161,\n",
       " 'further': 162,\n",
       " 'no': 163,\n",
       " 'study': 164,\n",
       " 'rates': 165,\n",
       " 'improve': 166,\n",
       " 'weight': 167,\n",
       " 'up': 168,\n",
       " 'technique': 169,\n",
       " 'l': 170,\n",
       " '1': 171,\n",
       " 'accuracy': 172,\n",
       " 'its': 173,\n",
       " 'demonstrate': 174,\n",
       " 'acoustic': 175,\n",
       " 'small': 176,\n",
       " 'test': 177,\n",
       " 'existing': 178,\n",
       " 'better': 179,\n",
       " 'they': 180,\n",
       " 'rate': 181,\n",
       " 'shown': 182,\n",
       " 'achieve': 183,\n",
       " 'important': 184,\n",
       " 'computational': 185,\n",
       " 'very': 186,\n",
       " 'benchmark': 187,\n",
       " 'image': 188,\n",
       " 'matrix': 189,\n",
       " 'samples': 190,\n",
       " 'achieved': 191,\n",
       " 'several': 192,\n",
       " 'lstm': 193,\n",
       " 'representation': 194,\n",
       " 'may': 195,\n",
       " 'objective': 196,\n",
       " 'find': 197,\n",
       " 'theoretical': 198,\n",
       " 'compared': 199,\n",
       " 'high': 200,\n",
       " 'conventional': 201,\n",
       " 'depth': 202,\n",
       " 'context': 203,\n",
       " 'then': 204,\n",
       " 'theory': 205,\n",
       " 'long': 206,\n",
       " 'mnist': 207,\n",
       " 'f': 208,\n",
       " 'supervised': 209,\n",
       " 'wise': 210,\n",
       " 'out': 211,\n",
       " 'even': 212,\n",
       " 'parameter': 213,\n",
       " 'random': 214,\n",
       " 'where': 215,\n",
       " 'batch': 216,\n",
       " 'complexity': 217,\n",
       " 'backpropagation': 218,\n",
       " 'empirical': 219,\n",
       " 'system': 220,\n",
       " 'memory': 221,\n",
       " 'current': 222,\n",
       " 'weights': 223,\n",
       " 'cifar': 224,\n",
       " 'properties': 225,\n",
       " 'inference': 226,\n",
       " 'directly': 227,\n",
       " 'e': 228,\n",
       " 'any': 229,\n",
       " 'general': 230,\n",
       " 'space': 231,\n",
       " 'providing': 232,\n",
       " 'within': 233,\n",
       " 'iterations': 234,\n",
       " 'given': 235,\n",
       " 'faster': 236,\n",
       " 'parallel': 237,\n",
       " 'various': 238,\n",
       " 'best': 239,\n",
       " 'machines': 240,\n",
       " 'dataset': 241,\n",
       " 'reduction': 242,\n",
       " 'loss': 243,\n",
       " 'about': 244,\n",
       " 'autoencoder': 245,\n",
       " 'sparse': 246,\n",
       " 'gradients': 247,\n",
       " 'term': 248,\n",
       " 'application': 249,\n",
       " 'target': 250,\n",
       " 'maxout': 251,\n",
       " 'prediction': 252,\n",
       " 'why': 253,\n",
       " 'knowledge': 254,\n",
       " 'three': 255,\n",
       " 'adversarial': 256,\n",
       " 'learned': 257,\n",
       " 'group': 258,\n",
       " 'object': 259,\n",
       " 'distributed': 260,\n",
       " 'leads': 261,\n",
       " 'some': 262,\n",
       " 'without': 263,\n",
       " 'during': 264,\n",
       " 'approximation': 265,\n",
       " 'improvement': 266,\n",
       " 'much': 267,\n",
       " 'previous': 268,\n",
       " 'sgd': 269,\n",
       " 'able': 270,\n",
       " 'log': 271,\n",
       " 'effective': 272,\n",
       " 'hessian': 273,\n",
       " 'sequence': 274,\n",
       " 'multiple': 275,\n",
       " 'dimensional': 276,\n",
       " 'amount': 277,\n",
       " 'regularization': 278,\n",
       " 'low': 279,\n",
       " 'does': 280,\n",
       " 'so': 281,\n",
       " 'result': 282,\n",
       " 'effectiveness': 283,\n",
       " 'do': 284,\n",
       " 'feature': 285,\n",
       " 'ensemble': 286,\n",
       " 'significantly': 287,\n",
       " 'similar': 288,\n",
       " 'factor': 289,\n",
       " 'bootstrap': 290,\n",
       " 'mbn': 291,\n",
       " 'images': 292,\n",
       " 'language': 293,\n",
       " 'vision': 294,\n",
       " 'coordinates': 295,\n",
       " 'competitive': 296,\n",
       " 'initial': 297,\n",
       " 'relative': 298,\n",
       " 'related': 299,\n",
       " 'contrast': 300,\n",
       " 'powerful': 301,\n",
       " 'limited': 302,\n",
       " 'adaptation': 303,\n",
       " 'free': 304,\n",
       " '2': 305,\n",
       " 'speed': 306,\n",
       " 'communication': 307,\n",
       " 'point': 308,\n",
       " 'here': 309,\n",
       " 'applications': 310,\n",
       " 'nets': 311,\n",
       " 'autoencoders': 312,\n",
       " 'efficiently': 313,\n",
       " 'same': 314,\n",
       " 'higher': 315,\n",
       " 'average': 316,\n",
       " 'norm': 317,\n",
       " '10': 318,\n",
       " 'deeper': 319,\n",
       " 'g': 320,\n",
       " 'transfer': 321,\n",
       " 'channel': 322,\n",
       " 'sample': 323,\n",
       " 'power': 324,\n",
       " 'thus': 325,\n",
       " 'capacity': 326,\n",
       " 'operations': 327,\n",
       " 'applied': 328,\n",
       " 'capture': 329,\n",
       " 'rules': 330,\n",
       " 'hf': 331,\n",
       " 'signals': 332,\n",
       " 'often': 333,\n",
       " 'hierarchical': 334,\n",
       " 'computer': 335,\n",
       " 'optimal': 336,\n",
       " 'widely': 337,\n",
       " 'difficult': 338,\n",
       " 'significant': 339,\n",
       " 'strategy': 340,\n",
       " 'constrained': 341,\n",
       " 'available': 342,\n",
       " 'known': 343,\n",
       " 'variables': 344,\n",
       " 'variety': 345,\n",
       " 'cnn': 346,\n",
       " '3': 347,\n",
       " 'popular': 348,\n",
       " 'like': 349,\n",
       " 'scheme': 350,\n",
       " 'fixed': 351,\n",
       " 'suggest': 352,\n",
       " 'pretraining': 353,\n",
       " 'explore': 354,\n",
       " 'obtain': 355,\n",
       " 'particular': 356,\n",
       " 'successful': 357,\n",
       " '100': 358,\n",
       " 'efficient': 359,\n",
       " 'terms': 360,\n",
       " 'predictions': 361,\n",
       " 'modeling': 362,\n",
       " 'successfully': 363,\n",
       " 'outperforms': 364,\n",
       " 'benchmarks': 365,\n",
       " 'feedforward': 366,\n",
       " 'activation': 367,\n",
       " 'generalization': 368,\n",
       " 'was': 369,\n",
       " 'perform': 370,\n",
       " 'resulting': 371,\n",
       " 'most': 372,\n",
       " 'form': 373,\n",
       " 'forward': 374,\n",
       " 'encoder': 375,\n",
       " 'class': 376,\n",
       " 'success': 377,\n",
       " 'relevant': 378,\n",
       " 'distribution': 379,\n",
       " 'types': 380,\n",
       " 'challenging': 381,\n",
       " 'groups': 382,\n",
       " 'cif': 383,\n",
       " 'nonlinear': 384,\n",
       " 'inspired': 385,\n",
       " 'nonconvex': 386,\n",
       " 'called': 387,\n",
       " 'easy': 388,\n",
       " 'setting': 389,\n",
       " 'settings': 390,\n",
       " 'designed': 391,\n",
       " 'advantage': 392,\n",
       " 'search': 393,\n",
       " 'improvements': 394,\n",
       " 'variance': 395,\n",
       " 'reduced': 396,\n",
       " 'speedup': 397,\n",
       " 'due': 398,\n",
       " 'cnns': 399,\n",
       " 'reduce': 400,\n",
       " 'wer': 401,\n",
       " 'full': 402,\n",
       " 'apply': 403,\n",
       " 'larger': 404,\n",
       " 'process': 405,\n",
       " 'cluster': 406,\n",
       " 'obtained': 407,\n",
       " 'need': 408,\n",
       " 'respect': 409,\n",
       " 'aspects': 410,\n",
       " 'address': 411,\n",
       " 'bounds': 412,\n",
       " 'evaluate': 413,\n",
       " 'constraints': 414,\n",
       " 'estimate': 415,\n",
       " 'provides': 416,\n",
       " 'independent': 417,\n",
       " 'works': 418,\n",
       " 'step': 419,\n",
       " 'introduced': 420,\n",
       " 'manifold': 421,\n",
       " 'short': 422,\n",
       " 'fully': 423,\n",
       " 'typically': 424,\n",
       " 'predictive': 425,\n",
       " 'kernel': 426,\n",
       " 'temporal': 427,\n",
       " 'although': 428,\n",
       " 'targets': 429,\n",
       " 'inputs': 430,\n",
       " 'investigate': 431,\n",
       " 'provided': 432,\n",
       " 'empirically': 433,\n",
       " 'path': 434,\n",
       " 'regularizer': 435,\n",
       " 'max': 436,\n",
       " 'multilayer': 437,\n",
       " 'difficulties': 438,\n",
       " 'allows': 439,\n",
       " 'multiplicative': 440,\n",
       " 'experimental': 441,\n",
       " 'feed': 442,\n",
       " 'matrices': 443,\n",
       " 'probabilistic': 444,\n",
       " 'decoder': 445,\n",
       " 'level': 446,\n",
       " 'allow': 447,\n",
       " 'computationally': 448,\n",
       " 'including': 449,\n",
       " 'potential': 450,\n",
       " 'mechanism': 451,\n",
       " 'top': 452,\n",
       " 'main': 453,\n",
       " 'i': 454,\n",
       " 'making': 455,\n",
       " 'factors': 456,\n",
       " 'generators': 457,\n",
       " 'requires': 458,\n",
       " 'whose': 459,\n",
       " 'em': 460,\n",
       " 'principle': 461,\n",
       " 'dbn': 462,\n",
       " 'rpu': 463,\n",
       " 'clustering': 464,\n",
       " 'rfns': 465,\n",
       " 'h': 466,\n",
       " 'nested': 467,\n",
       " 'achieves': 468,\n",
       " 'example': 469,\n",
       " 'artificial': 470,\n",
       " 'end': 471,\n",
       " 'selection': 472,\n",
       " 'practice': 473,\n",
       " 'describe': 474,\n",
       " 'few': 475,\n",
       " 'poor': 476,\n",
       " 'starting': 477,\n",
       " 'help': 478,\n",
       " 'could': 479,\n",
       " 'found': 480,\n",
       " 'solution': 481,\n",
       " 'svrg': 482,\n",
       " 'almost': 483,\n",
       " 'convexity': 484,\n",
       " 'extend': 485,\n",
       " 'mini': 486,\n",
       " '4': 487,\n",
       " 'second': 488,\n",
       " 'support': 489,\n",
       " 'tensor': 490,\n",
       " 'scales': 491,\n",
       " 'furthermore': 492,\n",
       " 'through': 493,\n",
       " 'develop': 494,\n",
       " 'since': 495,\n",
       " 'cannot': 496,\n",
       " 'especially': 497,\n",
       " 'understanding': 498,\n",
       " 'denoising': 499,\n",
       " 'question': 500,\n",
       " 'if': 501,\n",
       " 'certain': 502,\n",
       " 'derived': 503,\n",
       " 'possible': 504,\n",
       " 'developed': 505,\n",
       " 'parallelism': 506,\n",
       " 'essential': 507,\n",
       " 'parmac': 508,\n",
       " 'trains': 509,\n",
       " 'consider': 510,\n",
       " 'case': 511,\n",
       " 'risk': 512,\n",
       " 'little': 513,\n",
       " 'role': 514,\n",
       " 'connected': 515,\n",
       " 'construct': 516,\n",
       " 'curvature': 517,\n",
       " 'previously': 518,\n",
       " 'margin': 519,\n",
       " 'exponentially': 520,\n",
       " 'specific': 521,\n",
       " 'rectifier': 522,\n",
       " 'via': 523,\n",
       " 'thereby': 524,\n",
       " 'invariant': 525,\n",
       " 'analyzing': 526,\n",
       " 'improves': 527,\n",
       " 'literature': 528,\n",
       " 'shallow': 529,\n",
       " 'shape': 530,\n",
       " 'accurate': 531,\n",
       " 'belief': 532,\n",
       " 'propagation': 533,\n",
       " 'stacking': 534,\n",
       " 'outperform': 535,\n",
       " 'boltzmann': 536,\n",
       " 'teacher': 537,\n",
       " 'connections': 538,\n",
       " 'structured': 539,\n",
       " 'sparsity': 540,\n",
       " 'computing': 541,\n",
       " 'generative': 542,\n",
       " 'focus': 543,\n",
       " 'cost': 544,\n",
       " 'per': 545,\n",
       " 'preliminary': 546,\n",
       " 'et': 547,\n",
       " 'al': 548,\n",
       " 'neuronal': 549,\n",
       " 'generalized': 550,\n",
       " 'gated': 551,\n",
       " 'procedure': 552,\n",
       " 'randomly': 553,\n",
       " 'noise': 554,\n",
       " 'pseudo': 555,\n",
       " 'transformation': 556,\n",
       " 'scaling': 557,\n",
       " 'dimensionality': 558,\n",
       " 'distillation': 559,\n",
       " 'stacked': 560,\n",
       " 'applying': 561,\n",
       " 'values': 562,\n",
       " 'probability': 563,\n",
       " 'normalization': 564,\n",
       " 'series': 565,\n",
       " 'source': 566,\n",
       " 'domains': 567,\n",
       " 'individual': 568,\n",
       " 'hierarchy': 569,\n",
       " 'human': 570,\n",
       " 'auxiliary': 571,\n",
       " 'mac': 572,\n",
       " 'involving': 573,\n",
       " 'implement': 574,\n",
       " 'common': 575,\n",
       " 'good': 576,\n",
       " 'get': 577,\n",
       " 'involves': 578,\n",
       " 're': 579,\n",
       " 'whole': 580,\n",
       " 'sum': 581,\n",
       " 'analyze': 582,\n",
       " 'global': 583,\n",
       " 'variants': 584,\n",
       " 'signal': 585,\n",
       " 'sharing': 586,\n",
       " 'effectively': 587,\n",
       " 'additional': 588,\n",
       " 'baseline': 589,\n",
       " '5': 590,\n",
       " 'frameworks': 591,\n",
       " 'multi': 592,\n",
       " 'overhead': 593,\n",
       " 'imagenet': 594,\n",
       " 'increases': 595,\n",
       " 'studied': 596,\n",
       " 'less': 597,\n",
       " 'mechanisms': 598,\n",
       " 'objectives': 599,\n",
       " 'building': 600,\n",
       " 'insights': 601,\n",
       " 'levels': 602,\n",
       " 'iterative': 603,\n",
       " 'reconstruction': 604,\n",
       " 'steps': 605,\n",
       " 'approximate': 606,\n",
       " 'fundamental': 607,\n",
       " 'converges': 608,\n",
       " 'smooth': 609,\n",
       " 'suitable': 610,\n",
       " 'ability': 611,\n",
       " 'represent': 612,\n",
       " 'piecewise': 613,\n",
       " 'mapping': 614,\n",
       " 'asr': 615,\n",
       " 'combines': 616,\n",
       " 'final': 617,\n",
       " 'takes': 618,\n",
       " 'precision': 619,\n",
       " 'computations': 620,\n",
       " 'behavior': 621,\n",
       " 'energy': 622,\n",
       " 'required': 623,\n",
       " 'preserving': 624,\n",
       " 'embedded': 625,\n",
       " 'us': 626,\n",
       " 'rectified': 627,\n",
       " 'discovery': 628,\n",
       " 'locality': 629,\n",
       " 'finally': 630,\n",
       " '0': 631,\n",
       " 'distance': 632,\n",
       " 'theoretically': 633,\n",
       " 'adaptive': 634,\n",
       " 'visual': 635,\n",
       " 'tricks': 636,\n",
       " 'superior': 637,\n",
       " 'convnets': 638,\n",
       " 'perspective': 639,\n",
       " 'relationship': 640,\n",
       " 'make': 641,\n",
       " 'deterministic': 642,\n",
       " 'unclear': 643,\n",
       " 'associated': 644,\n",
       " 'markov': 645,\n",
       " 'factorization': 646,\n",
       " 'despite': 647,\n",
       " 'build': 648,\n",
       " 'decomposition': 649,\n",
       " 'require': 650,\n",
       " 'promising': 651,\n",
       " 'restricted': 652,\n",
       " 'demonstrated': 653,\n",
       " 'rprop': 654,\n",
       " 'improved': 655,\n",
       " 'real': 656,\n",
       " 'direct': 657,\n",
       " 'uses': 658,\n",
       " 'corresponding': 659,\n",
       " 'unknown': 660,\n",
       " 'discriminative': 661,\n",
       " 'successes': 662,\n",
       " 'formalize': 663,\n",
       " 'against': 664,\n",
       " 'outputs': 665,\n",
       " 'classes': 666,\n",
       " '2012': 667,\n",
       " 'gating': 668,\n",
       " 'increase': 669,\n",
       " 'increasing': 670,\n",
       " 'combining': 671,\n",
       " 'therefore': 672,\n",
       " 'ii': 673,\n",
       " 'attention': 674,\n",
       " 'augmentation': 675,\n",
       " 'cd': 676,\n",
       " 'ctc': 677,\n",
       " 'examples': 678,\n",
       " 'unseen': 679,\n",
       " 'embedding': 680,\n",
       " 'connection': 681,\n",
       " 'unlike': 682,\n",
       " 'labeling': 683,\n",
       " 'relatively': 684,\n",
       " 'learns': 685,\n",
       " 'semi': 686,\n",
       " 'infinite': 687,\n",
       " 'child': 688,\n",
       " 'nodes': 689,\n",
       " 'divergence': 690,\n",
       " 'easily': 691,\n",
       " 'down': 692,\n",
       " 'expensive': 693,\n",
       " 'embeddings': 694,\n",
       " 'orders': 695,\n",
       " 'moreover': 696,\n",
       " 'selected': 697,\n",
       " 'continuous': 698,\n",
       " 'neurons': 699,\n",
       " 'propagated': 700,\n",
       " 'defined': 701,\n",
       " 'what': 702,\n",
       " 'explains': 703,\n",
       " 'graphs': 704,\n",
       " 'distributions': 705,\n",
       " 'defensive': 706,\n",
       " 'fact': 707,\n",
       " 'report': 708,\n",
       " 'orbits': 709,\n",
       " 'shadow': 710,\n",
       " 'likelihood': 711,\n",
       " 'value': 712,\n",
       " 'back': 713,\n",
       " 'batches': 714,\n",
       " 'efficiency': 715,\n",
       " 'gf': 716,\n",
       " 'mixtures': 717,\n",
       " 'arbitrary': 718,\n",
       " 'gasf': 719,\n",
       " 'rbm': 720,\n",
       " 'sound': 721,\n",
       " 'performed': 722,\n",
       " 'sometimes': 723,\n",
       " 'generally': 724,\n",
       " 'operation': 725,\n",
       " 'joint': 726,\n",
       " 'estimation': 727,\n",
       " 'considered': 728,\n",
       " 'effort': 729,\n",
       " 'mathematical': 730,\n",
       " 'original': 731,\n",
       " 'online': 732,\n",
       " 'nesterov': 733,\n",
       " 'acceleration': 734,\n",
       " 'optima': 735,\n",
       " 'attempt': 736,\n",
       " 'rather': 737,\n",
       " 'prove': 738,\n",
       " 'provably': 739,\n",
       " 'showing': 740,\n",
       " 'spectral': 741,\n",
       " 'variation': 742,\n",
       " 'word': 743,\n",
       " '12': 744,\n",
       " 'strategies': 745,\n",
       " 'incorporate': 746,\n",
       " 'speaker': 747,\n",
       " 'particularly': 748,\n",
       " 'days': 749,\n",
       " 'leveraging': 750,\n",
       " 'resources': 751,\n",
       " 'spark': 752,\n",
       " 'were': 753,\n",
       " 'asynchronous': 754,\n",
       " 'intensive': 755,\n",
       " 'sparknet': 756,\n",
       " 'deploy': 757,\n",
       " 'tuning': 758,\n",
       " 'compatible': 759,\n",
       " 'aims': 760,\n",
       " 'means': 761,\n",
       " 'krylov': 762,\n",
       " 'subspace': 763,\n",
       " 'flexible': 764,\n",
       " 'guarantees': 765,\n",
       " 'sampling': 766,\n",
       " 'whereas': 767,\n",
       " 'switchboard': 768,\n",
       " 'estimates': 769,\n",
       " 'structural': 770,\n",
       " 'interesting': 771,\n",
       " 'guide': 772,\n",
       " 'derive': 773,\n",
       " 'solving': 774,\n",
       " 'usually': 775,\n",
       " 'advances': 776,\n",
       " 'gives': 777,\n",
       " 'introduces': 778,\n",
       " 'rule': 779,\n",
       " 'updates': 780,\n",
       " 'runtime': 781,\n",
       " 'binary': 782,\n",
       " 'fast': 783,\n",
       " 'o': 784,\n",
       " 'varepsilon': 785,\n",
       " 'research': 786,\n",
       " 'near': 787,\n",
       " 'special': 788,\n",
       " 'modelling': 789,\n",
       " 'automatic': 790,\n",
       " 'blstm': 791,\n",
       " 'posterior': 792,\n",
       " '8': 793,\n",
       " 'effect': 794,\n",
       " 'rounding': 795,\n",
       " 'play': 796,\n",
       " 'crucial': 797,\n",
       " \"network's\": 798,\n",
       " 'accelerator': 799,\n",
       " 'implements': 800,\n",
       " 'essentially': 801,\n",
       " 'operating': 802,\n",
       " 'replace': 803,\n",
       " 'allowing': 804,\n",
       " 'combine': 805,\n",
       " 'drop': 806,\n",
       " 'subset': 807,\n",
       " 'r': 808,\n",
       " 'bound': 809,\n",
       " 'depends': 810,\n",
       " 'dimension': 811,\n",
       " 'drug': 812,\n",
       " 'qsar': 813,\n",
       " 'bioactivity': 814,\n",
       " 'predict': 815,\n",
       " 'interactions': 816,\n",
       " 'filters': 817,\n",
       " 'diverse': 818,\n",
       " 'activations': 819,\n",
       " 'patterns': 820,\n",
       " 'compositional': 821,\n",
       " 'enables': 822,\n",
       " 'maps': 823,\n",
       " 'employ': 824,\n",
       " 'preserves': 825,\n",
       " 'directions': 826,\n",
       " 'decision': 827,\n",
       " 'decay': 828,\n",
       " 'customer': 829,\n",
       " 'represented': 830,\n",
       " 'churn': 831,\n",
       " 'labeled': 832,\n",
       " 'reasons': 833,\n",
       " 'taken': 834,\n",
       " 'strong': 835,\n",
       " 'users': 836,\n",
       " 'optimize': 837,\n",
       " 'argue': 838,\n",
       " 'gains': 839,\n",
       " 'proposes': 840,\n",
       " 'normalized': 841,\n",
       " 'lower': 842,\n",
       " 'adaptively': 843,\n",
       " 'those': 844,\n",
       " 'reported': 845,\n",
       " 'combined': 846,\n",
       " 'advantages': 847,\n",
       " 'optimizing': 848,\n",
       " 'mean': 849,\n",
       " 'fields': 850,\n",
       " 'negative': 851,\n",
       " 'sources': 852,\n",
       " 'yields': 853,\n",
       " 'update': 854,\n",
       " 'far': 855,\n",
       " 'fewer': 856,\n",
       " 'concept': 857,\n",
       " 'clear': 858,\n",
       " 'made': 859,\n",
       " 'alternative': 860,\n",
       " 'operators': 861,\n",
       " 'evaluated': 862,\n",
       " 'claim': 863,\n",
       " 'nature': 864,\n",
       " 'ones': 865,\n",
       " 'date': 866,\n",
       " 'corresponds': 867,\n",
       " 'rank': 868,\n",
       " 'tools': 869,\n",
       " 'measure': 870,\n",
       " 'implemented': 871,\n",
       " 'polynomial': 872,\n",
       " 'demonstrating': 873,\n",
       " 'ideas': 874,\n",
       " 'employed': 875,\n",
       " 'components': 876,\n",
       " 'soft': 877,\n",
       " 'modification': 878,\n",
       " 'pruning': 879,\n",
       " 'pattern': 880,\n",
       " 'guaranteed': 881,\n",
       " 'leverage': 882,\n",
       " 'under': 883,\n",
       " 'conditions': 884,\n",
       " 'challenge': 885,\n",
       " 'nuisance': 886,\n",
       " 'yield': 887,\n",
       " 'remains': 888,\n",
       " 'latent': 889,\n",
       " 'presented': 890,\n",
       " 'produce': 891,\n",
       " 'led': 892,\n",
       " 'great': 893,\n",
       " 'still': 894,\n",
       " 'part': 895,\n",
       " 'identify': 896,\n",
       " 'formulation': 897,\n",
       " 'exploit': 898,\n",
       " 'ratio': 899,\n",
       " 'conditional': 900,\n",
       " 'overfitting': 901,\n",
       " 'tree': 902,\n",
       " 'central': 903,\n",
       " 'careful': 904,\n",
       " 'themselves': 905,\n",
       " 'come': 906,\n",
       " 'blocks': 907,\n",
       " 'generalizes': 908,\n",
       " 'precisely': 909,\n",
       " 'key': 910,\n",
       " 'extension': 911,\n",
       " 'according': 912,\n",
       " 'four': 913,\n",
       " '30': 914,\n",
       " 'physics': 915,\n",
       " 'hmm': 916,\n",
       " 'phone': 917,\n",
       " 'lead': 918,\n",
       " 'formally': 919,\n",
       " 'vanishing': 920,\n",
       " 'exploding': 921,\n",
       " 'compare': 922,\n",
       " 'currently': 923,\n",
       " 'labels': 924,\n",
       " 'masking': 925,\n",
       " 'produces': 926,\n",
       " 'world': 927,\n",
       " 'sentiment': 928,\n",
       " 'existence': 929,\n",
       " 'contrastive': 930,\n",
       " 'approximations': 931,\n",
       " 'impact': 932,\n",
       " 'transformations': 933,\n",
       " 'inside': 934,\n",
       " 'amounts': 935,\n",
       " 'graph': 936,\n",
       " 'traditional': 937,\n",
       " 'generalize': 938,\n",
       " 'insight': 939,\n",
       " 'encoding': 940,\n",
       " 'locally': 941,\n",
       " 'must': 942,\n",
       " 'together': 943,\n",
       " 'backward': 944,\n",
       " 'maximum': 945,\n",
       " 'subject': 946,\n",
       " 'there': 947,\n",
       " 'natural': 948,\n",
       " 'encoded': 949,\n",
       " 'extremely': 950,\n",
       " 'studies': 951,\n",
       " 'shows': 952,\n",
       " 'creation': 953,\n",
       " 'tested': 954,\n",
       " 'learner': 955,\n",
       " 'validate': 956,\n",
       " 'commonly': 957,\n",
       " 'mdrnn': 958,\n",
       " 'fisher': 959,\n",
       " 'questions': 960,\n",
       " 'serve': 961,\n",
       " 'originally': 962,\n",
       " 'intuitively': 963,\n",
       " 'understood': 964,\n",
       " 'exact': 965,\n",
       " 'makes': 966,\n",
       " 'dbns': 967,\n",
       " 'yielded': 968,\n",
       " 'digit': 969,\n",
       " 'design': 970,\n",
       " 'corpus': 971,\n",
       " 'hours': 972,\n",
       " 'isometry': 973,\n",
       " 'highly': 974,\n",
       " 'vector': 975,\n",
       " 'walk': 976,\n",
       " 'property': 977,\n",
       " 'net': 978,\n",
       " 'overall': 979,\n",
       " 'character': 980,\n",
       " 'extraction': 981,\n",
       " 'compression': 982,\n",
       " 'compressive': 983,\n",
       " 'gprop': 984,\n",
       " 'reinforcement': 985,\n",
       " 'resnets': 986,\n",
       " 'rfn': 987,\n",
       " 'rbms': 988,\n",
       " 'estimated': 989,\n",
       " 'tiled': 990,\n",
       " 'bm': 991,\n",
       " 'sbm': 992,\n",
       " 'cdot': 993,\n",
       " 'minima': 994,\n",
       " 'erms': 995,\n",
       " 'datapoints': 996,\n",
       " 'rg': 997,\n",
       " 'science': 998,\n",
       " 'biologically': 999,\n",
       " 'generate': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ca3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(mytokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2ddef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading corpus the text file\n",
    "with open(\"chunk_1.txt\", 'r', encoding='utf-8') as myfile:\n",
    "    mytext1 = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4c696fe",
   "metadata": {
    "id": "c4c696fe"
   },
   "outputs": [],
   "source": [
    "my_input_sequences = []\n",
    "for line in mytext1.split('\\n'):\n",
    "    token_list = mytokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        my_n_gram_sequence = token_list[:i+1]\n",
    "        my_input_sequences.append(my_n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd13dce9",
   "metadata": {
    "id": "bd13dce9"
   },
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(seq) for seq in my_input_sequences])\n",
    "input_sequences = np.array(pad_sequences(my_input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf398edc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf398edc",
    "outputId": "47e6b408-f5a5-4558-f6f2-9c22da41efa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   6, 998,   5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce62fdd7",
   "metadata": {
    "id": "ce62fdd7"
   },
   "outputs": [],
   "source": [
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6385ea38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6385ea38",
    "outputId": "5dbabe6d-a146-42e4-926c-1f10c2c03307"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   6, 998])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc113505",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc113505",
    "outputId": "51485016-72d5-42ec-f963-828a9cb9a80d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 998,    5, 1453, ...,   17, 1323,  167])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ef255b4",
   "metadata": {
    "id": "2ef255b4"
   },
   "outputs": [],
   "source": [
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e13587e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e13587e",
    "outputId": "a710d5a1-ac32-4331-ca66-07c6ea326bda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28ac495c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "28ac495c",
    "outputId": "dfcce27d-0467-4619-f78d-df7f163a33e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 294, 100)          261900    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 294, 300)         301200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 294, 300)          0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 300)              541200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2619)              788319    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892,619\n",
      "Trainable params: 1,892,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(total_words, activation='softmax', kernel_regularizer=l2(0.01)))  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a4550a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 6.4798 - accuracy: 0.0882WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 225s 94ms/step - loss: 6.4798 - accuracy: 0.0882 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 6.1636 - accuracy: 0.1230WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 209s 89ms/step - loss: 6.1636 - accuracy: 0.1230 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 6.0415 - accuracy: 0.1424WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 207s 88ms/step - loss: 6.0415 - accuracy: 0.1424 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.9434 - accuracy: 0.1596WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 201s 85ms/step - loss: 5.9434 - accuracy: 0.1596 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.8315 - accuracy: 0.1744WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 208s 88ms/step - loss: 5.8315 - accuracy: 0.1744 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.7430 - accuracy: 0.1893WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 203s 86ms/step - loss: 5.7430 - accuracy: 0.1893 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.6552 - accuracy: 0.2022WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 204s 87ms/step - loss: 5.6552 - accuracy: 0.2022 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.5851 - accuracy: 0.2122WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 206s 88ms/step - loss: 5.5851 - accuracy: 0.2122 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.5598 - accuracy: 0.2151WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 203s 86ms/step - loss: 5.5598 - accuracy: 0.2151 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.4924 - accuracy: 0.2271WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 208s 88ms/step - loss: 5.4924 - accuracy: 0.2271 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.4736 - accuracy: 0.2325WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 207s 88ms/step - loss: 5.4736 - accuracy: 0.2325 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.4873 - accuracy: 0.2317WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 211s 90ms/step - loss: 5.4873 - accuracy: 0.2317 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.4413 - accuracy: 0.2395WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 211s 90ms/step - loss: 5.4413 - accuracy: 0.2395 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.4174 - accuracy: 0.2456WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 212s 90ms/step - loss: 5.4174 - accuracy: 0.2456 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3936 - accuracy: 0.2492WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 217s 92ms/step - loss: 5.3936 - accuracy: 0.2492 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3886 - accuracy: 0.2529WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 215s 91ms/step - loss: 5.3886 - accuracy: 0.2529 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3995 - accuracy: 0.2545WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 215s 91ms/step - loss: 5.3995 - accuracy: 0.2545 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3920 - accuracy: 0.2578WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 216s 92ms/step - loss: 5.3920 - accuracy: 0.2578 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3878 - accuracy: 0.2594WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 217s 92ms/step - loss: 5.3878 - accuracy: 0.2594 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3485 - accuracy: 0.2679WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 220s 94ms/step - loss: 5.3485 - accuracy: 0.2679 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3372 - accuracy: 0.2720WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 218s 93ms/step - loss: 5.3372 - accuracy: 0.2720 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3301 - accuracy: 0.2750WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 222s 94ms/step - loss: 5.3301 - accuracy: 0.2750 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3078 - accuracy: 0.2779WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 225s 96ms/step - loss: 5.3078 - accuracy: 0.2779 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.3095 - accuracy: 0.2800WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 219s 93ms/step - loss: 5.3095 - accuracy: 0.2800 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 5.2792 - accuracy: 0.2846WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "2352/2352 [==============================] - 224s 95ms/step - loss: 5.2792 - accuracy: 0.2846 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee3cdbda30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X, y, epochs=25, verbose=1,batch_size=64,callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc30fe17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc30fe17",
    "outputId": "5abb6e0c-b3c6-4426-b691-8048a5736cf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 20]\n",
      "1/1 [==============================] - 1s 764ms/step\n",
      "[13, 20, 593]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[13, 20, 593, 593]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[13, 20, 593, 593, 593]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[13, 20, 593, 593, 593, 593]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[13, 20, 593, 593, 593, 593, 593]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Neural Network overhead overhead overhead overhead overhead overhead\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Neural Network\"\n",
    "predict_next_words= 6\n",
    "\n",
    "for _ in range(predict_next_words):\n",
    "    token_list = mytokenizer.texts_to_sequences([input_text])[0]\n",
    "    print(token_list)\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "    for word, index in mytokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    input_text += \" \" + output_word\n",
    "\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2b46fa7",
   "metadata": {
    "id": "c2b46fa7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b55439c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model('my_model')\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66fd2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"chunk_4.txt\", 'r', encoding='utf-8') as myfile:\n",
    "    mytext2 = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e121e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input_sequences = []\n",
    "for line in mytext2.split('\\n'):\n",
    "    token_list = mytokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        my_n_gram_sequence = token_list[:i+1]\n",
    "        my_input_sequences.append(my_n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d64f15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(seq) for seq in my_input_sequences])\n",
    "input_sequences = np.array(pad_sequences(my_input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd8e49f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dfd5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "162d030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2354/2354 [==============================] - 182s 76ms/step - loss: 6.5007 - accuracy: 0.0843 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "2354/2354 [==============================] - 180s 77ms/step - loss: 6.1713 - accuracy: 0.1197 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "2354/2354 [==============================] - 215s 92ms/step - loss: 6.0537 - accuracy: 0.1442 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "2354/2354 [==============================] - 203s 86ms/step - loss: 5.9495 - accuracy: 0.1577 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "2354/2354 [==============================] - 191s 81ms/step - loss: 5.8648 - accuracy: 0.1746 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "2354/2354 [==============================] - 192s 82ms/step - loss: 5.7732 - accuracy: 0.1911 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "2354/2354 [==============================] - 205s 87ms/step - loss: 5.6883 - accuracy: 0.2053 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "2354/2354 [==============================] - 194s 82ms/step - loss: 5.6667 - accuracy: 0.2125 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "2354/2354 [==============================] - 184s 78ms/step - loss: 5.5856 - accuracy: 0.2235 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "2354/2354 [==============================] - 181s 77ms/step - loss: 5.5396 - accuracy: 0.2334 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "2354/2354 [==============================] - 182s 77ms/step - loss: 5.5125 - accuracy: 0.2417 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "2354/2354 [==============================] - 180s 77ms/step - loss: 5.4838 - accuracy: 0.2481 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "2354/2354 [==============================] - 183s 78ms/step - loss: 5.4416 - accuracy: 0.2544 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "2354/2354 [==============================] - 182s 77ms/step - loss: 5.4222 - accuracy: 0.2594 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "2354/2354 [==============================] - 182s 77ms/step - loss: 5.4069 - accuracy: 0.2628 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "2354/2354 [==============================] - 182s 77ms/step - loss: 5.3543 - accuracy: 0.2707 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "2354/2354 [==============================] - 182s 77ms/step - loss: 5.3552 - accuracy: 0.2726 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "2354/2354 [==============================] - 180s 76ms/step - loss: 5.3351 - accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "2354/2354 [==============================] - 181s 77ms/step - loss: 5.3390 - accuracy: 0.2761 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "2354/2354 [==============================] - 180s 76ms/step - loss: 5.2974 - accuracy: 0.2832 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "2354/2354 [==============================] - 182s 77ms/step - loss: 5.2762 - accuracy: 0.2877 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "2354/2354 [==============================] - 181s 77ms/step - loss: 5.2697 - accuracy: 0.2888 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "2354/2354 [==============================] - 182s 77ms/step - loss: 5.2539 - accuracy: 0.2913 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "2354/2354 [==============================] - 180s 76ms/step - loss: 5.2498 - accuracy: 0.2929 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "2354/2354 [==============================] - 180s 77ms/step - loss: 5.2617 - accuracy: 0.2914 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c222050310>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.fit(X, y, epochs=25, verbose=1,batch_size=64,callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "066ef2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_49_layer_call_fn, lstm_cell_49_layer_call_and_return_conditional_losses, lstm_cell_50_layer_call_fn, lstm_cell_50_layer_call_and_return_conditional_losses, lstm_cell_52_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "loaded_model.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04bbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model('my_model')\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db133ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "overfitting the network is used\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Neural Network\" \n",
    "predict_next_words= 4\n",
    "\n",
    "for _ in range(predict_next_words):\n",
    "    token_list = mytokenizer.texts_to_sequences([input_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(loaded_model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "    for word, index in mytokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    input_text += \" \" + output_word\n",
    "\n",
    "print(input_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
